{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP7SmykVtT/PaNjV60cr5g0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaveeMishra/Sentiment_analysis/blob/main/INSTA_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%writefile requirements.txt\n",
        "\n",
        "numpy==1.26.4\n",
        "scikit-learn==1.4.2\n",
        "torch==2.2.2\n",
        "transformers==4.41.2\n",
        "datasets==2.18.0\n",
        "tqdm\n",
        "pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRvsbL7gnIgB",
        "outputId": "5cff372c-0621-44f0-cb04-cf4ff75a3f07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "li8svxN7nPtS",
        "outputId": "df75cf08-b159-4426-c355-ac22153c08c2",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m51.2/61.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m953.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.4.2 (from -r requirements.txt (line 3))\n",
            "  Downloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting torch==2.2.2 (from -r requirements.txt (line 4))\n",
            "  Downloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting transformers==4.41.2 (from -r requirements.txt (line 5))\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==2.18.0 (from -r requirements.txt (line 6))\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.67.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers==4.41.2->-r requirements.txt (line 5))\n",
            "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (2.32.4)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.41.2->-r requirements.txt (line 5))\n",
            "  Downloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (18.1.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.18.0->-r requirements.txt (line 6))\n",
            "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (0.70.16)\n",
            "Collecting fsspec (from torch==2.2.2->-r requirements.txt (line 4))\n",
            "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (3.13.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 4)) (12.8.93)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (1.22.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (2026.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2->-r requirements.txt (line 4)) (1.3.0)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m90.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp312-cp312-manylinux1_x86_64.whl (755.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
            "Installing collected packages: pyarrow-hotfix, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, fsspec, nvidia-cusolver-cu12, nvidia-cudnn-cu12, huggingface-hub, torch, tokenizers, scikit-learn, transformers, datasets\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.0\n",
            "    Uninstalling huggingface_hub-1.4.0:\n",
            "      Successfully uninstalled huggingface_hub-1.4.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu128\n",
            "    Uninstalling torch-2.9.0+cu128:\n",
            "      Successfully uninstalled torch-2.9.0+cu128\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.22.2\n",
            "    Uninstalling tokenizers-0.22.2:\n",
            "      Successfully uninstalled tokenizers-0.22.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 5.0.0\n",
            "    Uninstalling transformers-5.0.0:\n",
            "      Successfully uninstalled transformers-5.0.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.24.0+cu128 requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.11 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "torchaudio 2.9.0+cu128 requires torch==2.9.0, but you have torch 2.2.2 which is incompatible.\n",
            "hdbscan 0.8.41 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.2.0 which is incompatible.\n",
            "opencv-python-headless 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.18.0 fsspec-2024.2.0 huggingface-hub-0.36.2 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 pyarrow-hotfix-0.7 scikit-learn-1.4.2 tokenizers-0.19.1 torch-2.2.2 transformers-4.41.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "669f59ae085f4f6ea512cf3b9da518d5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"INSTAGRAM_REVIEWS.csv\")\n",
        "\n",
        "# Keep only needed columns\n",
        "df = df[[\"review_text\", \"review_rating\"]]\n",
        "\n",
        "# Remove missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Create sentiment label\n",
        "def create_label(rating):\n",
        "    if rating >= 4:\n",
        "        return 1  # Positive\n",
        "    elif rating <= 2:\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        return None  # Neutral (we remove)\n",
        "\n",
        "df[\"label\"] = df[\"review_rating\"].apply(create_label)\n",
        "\n",
        "# Remove neutral reviews\n",
        "df = df.dropna(subset=[\"label\"])\n",
        "\n",
        "# Rename review_text to text (to match your training code)\n",
        "df = df.rename(columns={\"review_text\": \"text\"})\n",
        "\n",
        "# Convert label to integer\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "# Split (80% train / 20% test)\n",
        "train_df, test_df = train_test_split(\n",
        "    df[[\"text\", \"label\"]],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "# Save files\n",
        "train_df.to_csv(\"instagram_train.csv\", index=False)\n",
        "test_df.to_csv(\"instagram_test.csv\", index=False)\n",
        "\n",
        "print(\"Dataset prepared & split successfully ✔\")\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Test size:\", len(test_df))\n",
        "print(\"\\nLabel distribution (Train):\")\n",
        "print(train_df[\"label\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdMyA5N41tWV",
        "outputId": "1824f8b4-187b-46f0-b71c-02e9c8dad841"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared & split successfully ✔\n",
            "Train size: 2339688\n",
            "Test size: 584923\n",
            "\n",
            "Label distribution (Train):\n",
            "label\n",
            "1    1767852\n",
            "0     571836\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score , accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "############################################\n",
        "# CONFIG\n",
        "############################################\n",
        "\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 3\n",
        "LR = 2e-4\n",
        "MAX_LEN = 128\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "############################################\n",
        "# DATASET\n",
        "############################################\n",
        "\n",
        "class InstagramSentimentDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_path):\n",
        "\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        self.texts = df[\"text\"].tolist()\n",
        "        self.labels = df[\"label\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        enc = tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "def get_loader(csv_path, shuffle=True):\n",
        "\n",
        "    return DataLoader(\n",
        "        InstagramSentimentDataset(csv_path),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "\n",
        "############################################\n",
        "# MODELS (SAME AS YOUR CODE)\n",
        "############################################\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab=30522, embed=128):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, embed)\n",
        "\n",
        "        self.conv = nn.Conv1d(embed, 256, kernel_size=5)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, ids):\n",
        "\n",
        "        x = self.embedding(ids)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        x = torch.relu(self.conv(x))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab=30522, embed=128, hidden=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, embed)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            embed,\n",
        "            hidden,\n",
        "            batch_first=True,\n",
        "            bidirectional=True\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden * 2, 2)\n",
        "\n",
        "    def forward(self, ids):\n",
        "\n",
        "        x = self.embedding(ids)\n",
        "\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "\n",
        "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "\n",
        "        return self.fc(hidden)\n",
        "\n",
        "\n",
        "############################################\n",
        "# METRICS (UNCHANGED)\n",
        "############################################\n",
        "\n",
        "def compute_metrics(logits, labels):\n",
        "\n",
        "    probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "    preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "    return {\n",
        "        \"Precision\": precision_score(labels, preds),\n",
        "        \"Recall\": recall_score(labels, preds),\n",
        "        \"F1\": f1_score(labels, preds),\n",
        "        \"ROC-AUC\": roc_auc_score(labels, probs),\n",
        "        \"Accuracy\": accuracy_score(labels, preds)\n",
        "    }\n",
        "\n",
        "\n",
        "############################################\n",
        "# TRAINING\n",
        "############################################\n",
        "\n",
        "def evaluate(model, loader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch in loader:\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            logits = model(ids)\n",
        "\n",
        "            all_logits.append(logits)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    metrics = compute_metrics(\n",
        "        torch.cat(all_logits),\n",
        "        torch.cat(all_labels)\n",
        "    )\n",
        "\n",
        "    print(\"\\nEvaluation Metrics:\")\n",
        "    for k, v in metrics.items():\n",
        "        print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "\n",
        "def train(model_type=\"cnn\"):\n",
        "\n",
        "    train_loader = get_loader(\"instagram_train.csv\", shuffle=True)\n",
        "    test_loader = get_loader(\"instagram_test.csv\", shuffle=False)\n",
        "\n",
        "    if model_type == \"cnn\":\n",
        "        model = CNNClassifier().to(DEVICE)\n",
        "    else:\n",
        "        model = RNNClassifier().to(DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        model.train()\n",
        "        loop = tqdm(train_loader)\n",
        "\n",
        "        for batch in loop:\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            logits = model(ids)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_description(f\"Epoch {epoch+1}\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        evaluate(model, test_loader)\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{model_type}_instagram_sentiment.pt\")\n",
        "\n",
        "    print(\"\\nModel saved ✔\")\n",
        "\n",
        "\n",
        "############################################\n",
        "# KMEANS (UNSUPERVISED)\n",
        "############################################\n",
        "\n",
        "def run_kmeans():\n",
        "\n",
        "    print(\"\\nRunning KMeans clustering...\")\n",
        "\n",
        "    df = pd.read_csv(\"instagram_train.csv\")\n",
        "\n",
        "    texts = df[\"text\"][:5000]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=5000,\n",
        "        stop_words=\"english\"\n",
        "    )\n",
        "\n",
        "    X = vectorizer.fit_transform(texts)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    unique, counts = np.unique(kmeans.labels_, return_counts=True)\n",
        "\n",
        "    print(\"Cluster Distribution:\")\n",
        "    print(dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "############################################\n",
        "# MAIN\n",
        "############################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Device:\", DEVICE)\n",
        "\n",
        "    train(model_type=\"cnn\")\n",
        "\n",
        "    print('*' * 100)\n",
        "\n",
        "    train(model_type=\"rnn\")\n",
        "\n",
        "    print('*' * 100)\n",
        "\n",
        "    run_kmeans()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqEdrJjWmsAE",
        "outputId": "cf250f56-acfc-466e-a59b-fb76c30f0a67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 73116/73116 [15:19<00:00, 79.51it/s, loss=0.248]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Precision: 0.8939\n",
            "Recall: 0.9574\n",
            "F1: 0.9246\n",
            "ROC-AUC: 0.8878\n",
            "Accuracy: 0.8819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 73116/73116 [14:52<00:00, 81.88it/s, loss=1.07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Precision: 0.8977\n",
            "Recall: 0.9555\n",
            "F1: 0.9257\n",
            "ROC-AUC: 0.8899\n",
            "Accuracy: 0.8841\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 73116/73116 [14:59<00:00, 81.30it/s, loss=0.0837]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Precision: 0.9010\n",
            "Recall: 0.9524\n",
            "F1: 0.9260\n",
            "ROC-AUC: 0.8913\n",
            "Accuracy: 0.8850\n",
            "\n",
            "Model saved ✔\n",
            "****************************************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 73116/73116 [22:57<00:00, 53.07it/s, loss=0.915]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Precision: 0.8974\n",
            "Recall: 0.9560\n",
            "F1: 0.9258\n",
            "ROC-AUC: 0.8914\n",
            "Accuracy: 0.8842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 73116/73116 [22:42<00:00, 53.68it/s, loss=0.0798]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Precision: 0.8977\n",
            "Recall: 0.9587\n",
            "F1: 0.9272\n",
            "ROC-AUC: 0.8942\n",
            "Accuracy: 0.8862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 73116/73116 [22:39<00:00, 53.80it/s, loss=0.972]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Metrics:\n",
            "Precision: 0.8991\n",
            "Recall: 0.9577\n",
            "F1: 0.9274\n",
            "ROC-AUC: 0.8944\n",
            "Accuracy: 0.8868\n",
            "\n",
            "Model saved ✔\n",
            "****************************************************************************************************\n",
            "\n",
            "Running KMeans clustering...\n",
            "Cluster Distribution:\n",
            "{0: 3988, 1: 1012}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dTJN7s7xmr8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Txv9DxP-mr6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKaLgGmZmr4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IJKjsIufmryn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}