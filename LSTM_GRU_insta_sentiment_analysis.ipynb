{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMJ7BZuS8xSEcPfA4GcQ2oz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaveeMishra/Sentiment_analysis/blob/main/LSTM_GRU_insta_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "numpy==1.26.4\n",
        "scikit-learn==1.4.2\n",
        "torch==2.2.2\n",
        "transformers==4.41.2\n",
        "datasets==2.18.0\n",
        "tqdm\n",
        "pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTedtnxR4OAO",
        "outputId": "ecb71e41-e020-4050-fc68-79b79d866187"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdfso-IH4Pnb",
        "outputId": "dd7c22ab-227e-4164-c8cb-15e8cac3afbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn==1.4.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: torch==2.2.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.2.2)\n",
            "Requirement already satisfied: transformers==4.41.2 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.41.2)\n",
            "Requirement already satisfied: datasets==2.18.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (4.67.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn==1.4.2->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch==2.2.2->-r requirements.txt (line 4)) (12.1.105)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (0.36.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.41.2->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (18.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (0.7)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets==2.18.0->-r requirements.txt (line 6)) (3.13.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2->-r requirements.txt (line 4)) (12.8.93)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 8)) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets==2.18.0->-r requirements.txt (line 6)) (1.22.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.41.2->-r requirements.txt (line 5)) (2026.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.2.2->-r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.2->-r requirements.txt (line 4)) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n63zqg-a3taN",
        "outputId": "dd6fb0ef-245f-4b1a-a60b-067ec10cf44c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset prepared & split successfully 笨能n",
            "Train size: 2339688\n",
            "Test size: 584923\n",
            "\n",
            "Label distribution (Train):\n",
            "label\n",
            "1    1767852\n",
            "0     571836\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"INSTAGRAM_REVIEWS.csv\")\n",
        "\n",
        "# Keep only needed columns\n",
        "df = df[[\"review_text\", \"review_rating\"]]\n",
        "\n",
        "# Remove missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Create sentiment label\n",
        "def create_label(rating):\n",
        "    if rating >= 4:\n",
        "        return 1  # Positive\n",
        "    elif rating <= 2:\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        return None  # Neutral (we remove)\n",
        "\n",
        "df[\"label\"] = df[\"review_rating\"].apply(create_label)\n",
        "\n",
        "# Remove neutral reviews\n",
        "df = df.dropna(subset=[\"label\"])\n",
        "\n",
        "# Rename review_text to text (to match your training code)\n",
        "df = df.rename(columns={\"review_text\": \"text\"})\n",
        "\n",
        "# Convert label to integer\n",
        "df[\"label\"] = df[\"label\"].astype(int)\n",
        "\n",
        "# Split (80% train / 20% test)\n",
        "train_df, test_df = train_test_split(\n",
        "    df[[\"text\", \"label\"]],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "\n",
        "# Save files\n",
        "train_df.to_csv(\"instagram_train.csv\", index=False)\n",
        "test_df.to_csv(\"instagram_test.csv\", index=False)\n",
        "\n",
        "print(\"Dataset prepared & split successfully 笨能")\n",
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Test size:\", len(test_df))\n",
        "print(\"\\nLabel distribution (Train):\")\n",
        "print(train_df[\"label\"].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score , accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "############################################\n",
        "# CONFIG\n",
        "############################################\n",
        "\n",
        "MODEL_NAME = \"distilbert-base-uncased\"\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 3\n",
        "LR = 2e-4\n",
        "MAX_LEN = 128\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "\n",
        "\n",
        "############################################\n",
        "# DATASET\n",
        "############################################\n",
        "\n",
        "class InstagramSentimentDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_path):\n",
        "\n",
        "        df = pd.read_csv(csv_path)\n",
        "\n",
        "        self.texts = df[\"text\"].tolist()\n",
        "        self.labels = df[\"label\"].tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        enc = tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LEN,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"label\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "def get_loader(csv_path, shuffle=True):\n",
        "\n",
        "    return DataLoader(\n",
        "        InstagramSentimentDataset(csv_path),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=shuffle,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "############################################\n",
        "# MODELS\n",
        "############################################\n",
        "\n",
        "class SimpleLSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Single-layer, Unidirectional LSTM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab=30522, embed=128, hidden=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, embed)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed,\n",
        "            hidden_size=hidden,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden, 2)\n",
        "\n",
        "    def forward(self, ids):\n",
        "\n",
        "        x = self.embedding(ids)\n",
        "\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "\n",
        "        hidden = hidden[-1]  # Last layer hidden state\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "\n",
        "        return self.fc(hidden)\n",
        "\n",
        "\n",
        "class DeepLSTMClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-layer (Deep) LSTM\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab=30522, embed=128, hidden=256, layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, embed)\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embed,\n",
        "            hidden_size=hidden,\n",
        "            num_layers=layers,      # 沐･ Multiple stacked layers\n",
        "            batch_first=True,\n",
        "            bidirectional=True,     # Deep + Bidirectional\n",
        "            dropout=0.3             # Applied between layers\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden * 2, 2)\n",
        "\n",
        "    def forward(self, ids):\n",
        "\n",
        "        x = self.embedding(ids)\n",
        "\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "\n",
        "        # Concatenate last forward + backward states\n",
        "        hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "\n",
        "        return self.fc(hidden)\n"
      ],
      "metadata": {
        "id": "OFfoWZiC5VVS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############################################\n",
        "# MODELS (GRU VERSION)\n",
        "############################################\n",
        "\n",
        "class SimpleGRUClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Single-layer, Unidirectional GRU\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab=30522, embed=128, hidden=256):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, embed)\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embed,\n",
        "            hidden_size=hidden,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden, 2)\n",
        "\n",
        "    def forward(self, ids):\n",
        "\n",
        "        x = self.embedding(ids)\n",
        "\n",
        "        _, hidden = self.gru(x)\n",
        "\n",
        "        hidden = hidden[-1]   # Last layer hidden state\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "\n",
        "        return self.fc(hidden)\n",
        "\n",
        "\n",
        "class DeepGRUClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-layer (Deep) GRU - NOT bidirectional\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab=30522, embed=128, hidden=256, layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab, embed)\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=embed,\n",
        "            hidden_size=hidden,\n",
        "            num_layers=layers,   # 沐･ Stacked layers\n",
        "            batch_first=True,\n",
        "            bidirectional=False,\n",
        "            dropout=0.3          # Applied between layers\n",
        "        )\n",
        "\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(hidden, 2)\n",
        "\n",
        "    def forward(self, ids):\n",
        "\n",
        "        x = self.embedding(ids)\n",
        "\n",
        "        _, hidden = self.gru(x)\n",
        "\n",
        "        hidden = hidden[-1]  # Last layer final hidden state\n",
        "\n",
        "        hidden = self.dropout(hidden)\n",
        "\n",
        "        return self.fc(hidden)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-N_IAb1X33ru"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_type=\"simple\"):\n",
        "    train_loader = get_loader(\"instagram_train.csv\", shuffle=True)\n",
        "    test_loader = get_loader(\"instagram_test.csv\", shuffle=False)\n",
        "\n",
        "    if model_type == \"simple\":\n",
        "        model = SimpleGRUClassifier().to(DEVICE)\n",
        "\n",
        "    elif model_type == \"deep\":\n",
        "        model = DeepGRUClassifier().to(DEVICE)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Choose 'simple' or 'deep'\")\n"
      ],
      "metadata": {
        "id": "UukmIhhw4vLx"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    print(\"Device:\", DEVICE)\n",
        "\n",
        "    # Simple GRU\n",
        "    train(model_type=\"simple\")\n",
        "\n",
        "    print('*' * 100)\n",
        "\n",
        "    # Deep GRU\n",
        "    train(model_type=\"deep\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHk7vlvT4zG2",
        "outputId": "a5618407-15cd-4f46-f7d0-ea207839f4f6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "****************************************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "    print(\"Device:\", DEVICE)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Simple LSTM\n",
        "    # ----------------------------\n",
        "    train_loader = get_loader(\"instagram_train.csv\", shuffle=True)\n",
        "    test_loader = get_loader(\"instagram_test.csv\", shuffle=False)\n",
        "\n",
        "    simple_lstm_model = SimpleLSTMClassifier().to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(simple_lstm_model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop (same as before)\n",
        "    for epoch in range(EPOCHS):\n",
        "        simple_lstm_model.train()\n",
        "        loop = tqdm(train_loader)\n",
        "        for batch in loop:\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            logits = simple_lstm_model(ids)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_description(f\"Simple LSTM | Epoch {epoch+1}\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Evaluate after each epoch using your metrics function\n",
        "        evaluate(simple_lstm_model, test_loader, model_name=\"Simple LSTM\")\n",
        "\n",
        "    torch.save(simple_lstm_model.state_dict(), \"simple_lstm_instagram.pt\")\n",
        "    print(\"Simple LSTM saved 笨能\n\")\n",
        "    print('*' * 100)\n",
        "\n",
        "    # ----------------------------\n",
        "    # Deep LSTM\n",
        "    # ----------------------------\n",
        "    deep_lstm_model = DeepLSTMClassifier().to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(deep_lstm_model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        deep_lstm_model.train()\n",
        "        loop = tqdm(train_loader)\n",
        "        for batch in loop:\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            logits = deep_lstm_model(ids)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_description(f\"Deep LSTM | Epoch {epoch+1}\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Evaluate after each epoch\n",
        "        evaluate(deep_lstm_model, test_loader, model_name=\"Deep LSTM\")\n",
        "\n",
        "    torch.save(deep_lstm_model.state_dict(), \"deep_lstm_instagram.pt\")\n",
        "    print(\"Deep LSTM saved 笨能\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AbvLTos-LFv",
        "outputId": "21fb4cfc-b334-4a94-8209-606e53c08ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Simple LSTM | Epoch 1: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 73116/73116 [19:44<00:00, 61.73it/s, loss=0.106]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Evaluation Metrics for Simple LSTM\n",
            "==================================================\n",
            "Precision  : 0.8936\n",
            "Recall     : 0.9595\n",
            "F1         : 0.9253\n",
            "ROC-AUC    : 0.8905\n",
            "Accuracy   : 0.8830\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Simple LSTM | Epoch 2: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 73116/73116 [19:28<00:00, 62.56it/s, loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Evaluation Metrics for Simple LSTM\n",
            "==================================================\n",
            "Precision  : 0.8998\n",
            "Recall     : 0.9554\n",
            "F1         : 0.9268\n",
            "ROC-AUC    : 0.8936\n",
            "Accuracy   : 0.8859\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Simple LSTM | Epoch 3: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 73116/73116 [19:41<00:00, 61.90it/s, loss=0.401]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Evaluation Metrics for Simple LSTM\n",
            "==================================================\n",
            "Precision  : 0.8996\n",
            "Recall     : 0.9574\n",
            "F1         : 0.9276\n",
            "ROC-AUC    : 0.8944\n",
            "Accuracy   : 0.8871\n",
            "==================================================\n",
            "\n",
            "Simple LSTM saved 笨能n",
            "\n",
            "****************************************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deep LSTM | Epoch 1: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 73116/73116 [57:40<00:00, 21.13it/s, loss=0.253]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Evaluation Metrics for Deep LSTM\n",
            "==================================================\n",
            "Precision  : 0.9003\n",
            "Recall     : 0.9519\n",
            "F1         : 0.9254\n",
            "ROC-AUC    : 0.8916\n",
            "Accuracy   : 0.8840\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deep LSTM | Epoch 2: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 73116/73116 [57:55<00:00, 21.04it/s, loss=0.0633]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Evaluation Metrics for Deep LSTM\n",
            "==================================================\n",
            "Precision  : 0.8963\n",
            "Recall     : 0.9605\n",
            "F1         : 0.9273\n",
            "ROC-AUC    : 0.8938\n",
            "Accuracy   : 0.8862\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Deep LSTM | Epoch 3:  14%|笆遺枕        | 10135/73116 [08:03<49:12, 21.33it/s, loss=0.247]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model_type=\"simple\"):\n",
        "\n",
        "    train_loader = get_loader(\"instagram_train.csv\", shuffle=True)\n",
        "    test_loader = get_loader(\"instagram_test.csv\", shuffle=False)\n",
        "\n",
        "    # Select model\n",
        "    if model_type == \"simple\":\n",
        "        model = SimpleGRUClassifier().to(DEVICE)\n",
        "        model_name = \"Simple GRU\"\n",
        "\n",
        "    elif model_type == \"deep\":\n",
        "        model = DeepGRUClassifier().to(DEVICE)\n",
        "        model_name = \"Deep GRU\"\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Choose 'simple' or 'deep'\")\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        model.train()\n",
        "        loop = tqdm(train_loader)\n",
        "\n",
        "        for batch in loop:\n",
        "\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            logits = model(ids)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            loop.set_description(f\"{model_name} | Epoch {epoch+1}\")\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "\n",
        "        # Evaluate after each epoch\n",
        "        evaluate(model, test_loader, model_name)\n",
        "\n",
        "    torch.save(model.state_dict(), f\"{model_type}_instagram_sentiment.pt\")\n",
        "    print(f\"\\n{model_name} saved 笨能\n\")\n"
      ],
      "metadata": {
        "id": "vEbOsQeL5hwl"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(logits, labels):\n",
        "\n",
        "    probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
        "    preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "    return {\n",
        "        \"Precision\": precision_score(labels, preds),\n",
        "        \"Recall\": recall_score(labels, preds),\n",
        "        \"F1\": f1_score(labels, preds),\n",
        "        \"ROC-AUC\": roc_auc_score(labels, probs),\n",
        "        \"Accuracy\": accuracy_score(labels, preds)\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "anCZn4989UY7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, model_name=\"Model\"):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            labels = batch[\"label\"].to(DEVICE)\n",
        "\n",
        "            logits = model(ids)\n",
        "\n",
        "            all_logits.append(logits)\n",
        "            all_labels.append(labels)\n",
        "\n",
        "    # Concatenate all batches\n",
        "    logits = torch.cat(all_logits)\n",
        "    labels = torch.cat(all_labels)\n",
        "\n",
        "    # Compute metrics using your original function\n",
        "    metrics = compute_metrics(logits, labels)\n",
        "\n",
        "    # Print metrics nicely\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Evaluation Metrics for {model_name}\")\n",
        "    print(\"=\"*50)\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        print(f\"{metric_name:10s} : {metric_value:.4f}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    return metrics\n"
      ],
      "metadata": {
        "id": "3liAVz7I6B8x"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print(\"Device:\", DEVICE)\n",
        "\n",
        "    # Simple GRU\n",
        "    train(model_type=\"simple\")\n",
        "\n",
        "    print('*' * 100)\n",
        "\n",
        "    # Deep GRU\n",
        "    train(model_type=\"deep\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "s-f_dtdV6qj3",
        "outputId": "8874621f-de08-4366-b1f6-f7908c0d1b81"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Simple GRU | Epoch 1:  21%|笆遺毎        | 15153/73116 [04:31<17:17, 55.86it/s, loss=0.427]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1347148386.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Simple GRU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"simple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-983164414.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model_type)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CdhfE5Rl9Xkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}